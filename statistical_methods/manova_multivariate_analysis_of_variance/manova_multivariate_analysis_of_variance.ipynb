{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Analysis of Variance (MANOVA)\n",
    "\n",
    "MANOVA extends the ANOVA framework to multiple dependent variables, allowing for the assessment of the effect of independent variables on multiple outcomes simultaneously. This method is particularly useful for understanding complex interactions and effects in multidimensional data.\n",
    "\n",
    "#### Business Scenario\n",
    "\n",
    "In this analysis, we explore how different manufacturing shifts (morning, afternoon, night) impact key quality metrics of semiconductor products. The goal is to uncover whether shift timing is associated with variations in product quality, potentially due to differences in operating conditions or workforce performance.\n",
    "\n",
    "#### Objective\n",
    "\n",
    "The objective is to determine if semiconductor products produced during different production periods exhibit significant differences in their quality metrics. This could reveal the influence of factors such as raw materials, machinery conditions, or operational staff on product quality.\n",
    "\n",
    "#### Data Description\n",
    "\n",
    "The dataset comprises 300 observations representing different production batches. Four key quality metrics are tracked:\n",
    "- Defect Rate (%)\n",
    "- Production Yield (%)\n",
    "- Equipment Efficiency (%)\n",
    "- Product Reliability Score (1-10)\n",
    "\n",
    "Each batch is associated with one of three shifts: morning, afternoon, or night.\n",
    "\n",
    "#### Statistical Formula\n",
    "\n",
    "The MANOVA test uses the following formula to assess the differences across multiple dependent variables simultaneously:\n",
    "\n",
    "$$\n",
    "\\Lambda = \\frac{|E|}{|H+E|}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\Lambda$ is Wilks' Lambda,\n",
    "- $|E|$ is the determinant of the error (within-group) covariance matrix,\n",
    "- $|H+E|$ is the determinant of the combined (hypothesis plus error) covariance matrix.\n",
    "\n",
    "#### Python Code for MANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Multivariate linear model\n",
      "====================================================================\n",
      "                                                                    \n",
      "--------------------------------------------------------------------\n",
      "       Intercept          Value   Num DF  Den DF    F Value   Pr > F\n",
      "--------------------------------------------------------------------\n",
      "          Wilks' lambda    0.0006 4.0000 294.0000 115843.8648 0.0000\n",
      "         Pillai's trace    0.9994 4.0000 294.0000 115843.8648 0.0000\n",
      " Hotelling-Lawley trace 1576.1070 4.0000 294.0000 115843.8648 0.0000\n",
      "    Roy's greatest root 1576.1070 4.0000 294.0000 115843.8648 0.0000\n",
      "--------------------------------------------------------------------\n",
      "                                                                    \n",
      "---------------------------------------------------------------------\n",
      "            shift           Value   Num DF   Den DF   F Value  Pr > F\n",
      "---------------------------------------------------------------------\n",
      "             Wilks' lambda  0.9836  8.0000  588.0000   0.6100  0.7698\n",
      "            Pillai's trace  0.0165  8.0000  590.0000   0.6118  0.7683\n",
      "    Hotelling-Lawley trace  0.0166  8.0000  417.6806   0.6091  0.7704\n",
      "       Roy's greatest root  0.0112  4.0000  295.0000   0.8264  0.5092\n",
      "====================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.multivariate.manova import MANOVA\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate data\n",
    "data = {\n",
    "    'defect_rate': np.random.uniform(0.5, 2.0, 300),\n",
    "    'production_yield': np.random.uniform(95, 100, 300),\n",
    "    'equipment_efficiency': np.random.uniform(80, 100, 300),\n",
    "    'product_reliability_score': np.random.randint(1, 11, 300),\n",
    "    'shift': np.random.choice(['Morning', 'Afternoon', 'Night'], 300)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Preparing data for MANOVA\n",
    "manova_data = df.pivot(columns='shift', values=['defect_rate', 'production_yield', 'equipment_efficiency', 'product_reliability_score'])\n",
    "\n",
    "# Conducting MANOVA\n",
    "maov = MANOVA.from_formula('defect_rate + production_yield + equipment_efficiency + product_reliability_score ~ shift', data=df)\n",
    "print(maov.mv_test())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation  \n",
    "The results from a MANOVA (Multivariate Analysis of Variance) analysis, which tests for differences in multiple outcome variables across groups. In your case, the groups are defined by the manufacturing shifts ('shift'). The output includes several statistics: Wilks' lambda, Pillai's trace, Hotelling-Lawley trace, and Roy's greatest root. Each of these provides a different method for testing the hypothesis that the mean vectors of the dependent variables are the same across groups.\n",
    "\n",
    "**Interpretation of the Results:**\n",
    "\n",
    "**Intercept Tests:** These tests are checking the overall model excluding the effect of shifts. The extremely low p-value (< 0.0001 for all tests) indicates that the model, including all predictors other than 'shift', significantly predicts the outcome variables. This suggests that the variables in your model are collectively significant in explaining variation in the outcome measures.\n",
    "\n",
    "**Shift Tests:** These are the key results for your business scenario, assessing whether different manufacturing shifts (morning, afternoon, night) have a statistically significant impact on the quality metrics of semiconductor products (as represented by your outcome variables).\n",
    "\n",
    "- **Wilks' Lambda:** A value of 0.9836 with a p-value of 0.7698 indicates that there is no significant difference in the combined dependent variables between different shifts. Wilks' lambda is a measure of how much the group means deviate from the overall mean, and in this case, the high p-value suggests little to no deviation.\n",
    "\n",
    "- **Pillai's Trace:** Similar to Wilks' lambda, a Pillai's trace value of 0.0165 and a p-value of 0.7683 also suggest no significant effect of shift on the outcome variables.\n",
    "\n",
    "- **Hotelling-Lawley Trace:** Again, a value of 0.0166 with a p-value of 0.7704 supports the finding that shifts do not significantly affect the outcome variables.\n",
    "\n",
    "- **Roy's Greatest Root:** This statistic also indicates no significant difference between groups with a value of 0.0112 and a p-value of 0.5092.\n",
    "\n",
    "**Conclusion:**\n",
    "The MANOVA results suggest that the manufacturing shift (morning, afternoon, night) does not significantly impact the key quality metrics of semiconductor products. This finding implies that the variations in product quality metrics are not attributable to the timing of the manufacturing shifts. Other factors not captured by the shift variable, such as raw materials, machinery conditions, operational staff, or perhaps variables not included in this analysis, may influence the quality metrics more significantly.\n",
    "\n",
    "This insight can guide further investigation into what factors do impact quality metrics and may suggest that efforts to improve quality control or process efficiency focus on areas other than shift scheduling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BONUS: Opting for Alternative Models to Multivariate Analysis of Variance (MANOVA)\n",
    "\n",
    "MANOVA extends the ANOVA framework to multiple dependent variables, allowing for the assessment of the effect of independent variables on multiple outcomes simultaneously. This method is particularly useful for understanding complex interactions and effects in multidimensional data.\n",
    "\n",
    "#### Business Scenario: Evaluating Manufacturing Shifts in Semiconductor Production\n",
    "\n",
    "Given the SECOM Manufacturing Data, we explore how different manufacturing shifts (morning, afternoon, night) impact key quality metrics of semiconductor products. This analysis aims to uncover whether the shift timing is associated with variations in product quality, potentially due to differences in operating conditions or workforce performance.\n",
    "\n",
    "#### Objective\n",
    "\n",
    "The objective is to explore whether semiconductor products produced during different production periods exhibit significant differences in their quality metrics, potentially revealing the influence of factors like raw materials, machinery conditions, or operational staff.\n",
    "\n",
    "#### Data Preparation and Grouping\n",
    "\n",
    "The dataset comprises 1567 observations and 591 features, representing various sensor measurements. The 'Label' column indicates pass/fail outcomes, with -1 for a pass and 1 for a fail.\n",
    "\n",
    "##### Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count of data types:\n",
      "float64    590\n",
      "int64        1\n",
      "object       1\n",
      "Name: count, dtype: int64\n",
      "Percentage of missing values: 4.52%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "# Load the dataset\n",
    "data_path = '../../data/secom.data'\n",
    "labels_path = '../../data/secom_labels.data'\n",
    "data = pd.read_csv(data_path, sep=' ', header=None, na_values='NaN')\n",
    "labels = pd.read_csv(labels_path, sep=' ', header=None, na_values='NaN')\n",
    "\n",
    "# Combine data and labels\n",
    "combined_df = pd.concat([data, labels], axis=1)\n",
    "\n",
    "# Define column names\n",
    "# Name columns as \"Feature 1\", \"Feature 2\", ..., \"Feature 591\"\n",
    "feature_names = ['Feature ' + str(i+1) for i in range(590)]\n",
    "new_column_names = feature_names + ['Label', 'Timestamp']\n",
    "combined_df.columns = new_column_names\n",
    "\n",
    "# Find percentage of missing values\n",
    "def count_dtypes(df):\n",
    "    return df.dtypes.value_counts()\n",
    "print(f\"Total count of data types:\\n{count_dtypes(combined_df)}\")\n",
    "print(f\"Percentage of missing values: {round((combined_df.isna().sum().sum())/(combined_df.shape[0]*combined_df.shape[1])*100,2)}%\")\n",
    "\n",
    "# Handle missing values\n",
    "# Instantiate the KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5, weights='uniform', metric='nan_euclidean')\n",
    "\n",
    "# Perform imputation\n",
    "imputed_data = imputer.fit_transform(combined_df.drop(columns=['Label', 'Timestamp']))\n",
    "imputed_df = pd.DataFrame(imputed_data, columns=feature_names)\n",
    "\n",
    "# Reattach the 'Label' and 'Timestamp' columns\n",
    "imputed_df['Label'] = combined_df['Label']\n",
    "imputed_df['Timestamp'] = combined_df['Timestamp']\n",
    "\n",
    "# Convert 'Timestamp' to datetime\n",
    "imputed_df['Timestamp'] = pd.to_datetime(imputed_df['Timestamp'], dayfirst=True)\n",
    "\n",
    "# Segment time into morning, afternoon, and optionally night shifts\n",
    "imputed_df['Time_Segment'] = pd.cut(imputed_df['Timestamp'].dt.hour,\n",
    "                                       bins=[0, 12, 18, 24],\n",
    "                                       labels=['Morning', 'Afternoon', 'Night'],\n",
    "                                       right=False,\n",
    "                                       include_lowest=True)\n",
    "                                       \n",
    "# Separate features and outcome variable\n",
    "X = imputed_df.drop(['Label', 'Timestamp', 'Time_Segment'], axis=1)  # Drop non-numeric and outcome variable\n",
    "y = imputed_df['Label']  # Assuming 'Label' is encoded as numeric\n",
    "\n",
    "# Initialize SelectKBest with f_classif and K=20\n",
    "selector = SelectKBest(f_classif, k=20)\n",
    "\n",
    "# Fit and transform the data to select the top 20 features\n",
    "X_reduced = selector.fit_transform(X, y)\n",
    "\n",
    "# Get the boolean mask of selected features and column names\n",
    "mask = selector.get_support(indices=True)  # Get column indices of selected features\n",
    "selected_features = X.columns[mask]\n",
    "\n",
    "# Create a new DataFrame with the selected features\n",
    "selected_df = imputed_df[selected_features].copy()\n",
    "\n",
    "# Add back the 'Label' and any other necessary columns for further analysis or MANOVA\n",
    "selected_df['Label'] = imputed_df['Label']\n",
    "selected_df['Timestamp'] = imputed_df['Timestamp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocessing Summary and Decisions\n",
    "\n",
    "Based on the preprocessing results:\n",
    "- **Data Types**: The dataset predominantly consists of float64 types (590 features), with one int64 and one object type, indicating a mostly numerical dataset suitable for MANOVA.  \n",
    "\n",
    "- **Missing Values**: The percentage of missing values in the dataset is 4.52%. For the purposes of this MANOVA analysis, and to preserve as much data as possible, it is opted to use KNN imputation rather than dropping rows or columns with missing values. This approach allows to retain the entire dataset, ensuring that the analysis is as comprehensive as possible.\n",
    "KNN Imputation leverages the k-nearest neighbors algorithm to impute missing values based on the mean of the nearest neighbors found in the column space. This method is particularly well-suited to datasets like SECOM, where the relationships between different sensor readings (features) can help predict missing values with a reasonable degree of accuracy.\n",
    "\n",
    "- **Time Segment Proportions**:  \n",
    "\n",
    "    - Morning: 47.93%  \n",
    "    - Afternoon: 26.10%  \n",
    "    - Night: 25.97%  \n",
    "\n",
    "This indicates a slight imbalance in the dataset with a higher proportion of data from the morning shift. While MANOVA can handle some level of imbalance, extreme imbalances can affect the power of the test to detect differences. In non-MANOVA contexts, balancing techniques such as oversampling, undersampling, or synthetic data generation (e.g., SMOTE) could be considered to mitigate imbalance effects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking Assumptions for MANOVA**  \n",
    "\n",
    "MANOVA assumes multivariate normality, homogeneity of variance-covariance matrices, and absence of multicollinearity among dependent variables. Here are basic code snippets to start checking these assumptions:  \n",
    "\n",
    "**<u>Multivariate Normality</u>**  \n",
    "Multivariate normality can be assessed using the Shapiro-Wilk test for individual variables as a simple approach, though this is more relevant for univariate normality. For a comprehensive multivariate normality check, consider using Henze-Zirkler's or Mardia's tests, which are more complex and may require specialized statistical software or packages.\n",
    "\n",
    "Shapiro-Wilk Test Formula:  \n",
    "The Shapiro-Wilk test assesses the normality of a distribution. The test statistic $W$ is defined as:\n",
    "\n",
    "$$\n",
    "W = \\frac{\\left( \\sum_{i=1}^{n} a_i x_{(i)} \\right)^2}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $n$ is the sample size,\n",
    "- $x_{(i)}$ are the ordered sample values (from smallest to largest),\n",
    "- $a_i$ are constants generated from the covariances, variances, and means of the order statistics of a sample of size $n$ from a standard normal distribution,\n",
    "- $x_i$ are the sample observations,\n",
    "- $\\bar{x}$ is the sample mean.\n",
    "\n",
    "The $W$ statistic measures how closely a set of observations follows a normal distribution. A value of $W$ close to 1 indicates a distribution similar to the normal distribution. The p-value resulting from the test indicates the significance of the deviation from normality, with a small p-value (typically < 0.05) suggesting that the distribution of the data is not normal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Statistics</th>\n",
       "      <th>p-value</th>\n",
       "      <th>Normality</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Feature 437</th>\n",
       "      <td>0.138530</td>\n",
       "      <td>2.015859e-64</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 436</th>\n",
       "      <td>0.153225</td>\n",
       "      <td>4.203222e-64</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 435</th>\n",
       "      <td>0.192963</td>\n",
       "      <td>3.242018e-63</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 300</th>\n",
       "      <td>0.216809</td>\n",
       "      <td>1.151437e-62</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <td>0.267883</td>\n",
       "      <td>1.948696e-61</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 431</th>\n",
       "      <td>0.311364</td>\n",
       "      <td>2.479278e-60</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 432</th>\n",
       "      <td>0.323838</td>\n",
       "      <td>5.273853e-60</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 299</th>\n",
       "      <td>0.399628</td>\n",
       "      <td>6.783466e-58</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 164</th>\n",
       "      <td>0.463181</td>\n",
       "      <td>6.041847e-56</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 296</th>\n",
       "      <td>0.493085</td>\n",
       "      <td>5.843182e-55</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 161</th>\n",
       "      <td>0.536024</td>\n",
       "      <td>1.864932e-53</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 511</th>\n",
       "      <td>0.670237</td>\n",
       "      <td>7.434598e-48</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 349</th>\n",
       "      <td>0.675894</td>\n",
       "      <td>1.401322e-47</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 211</th>\n",
       "      <td>0.708572</td>\n",
       "      <td>6.596441e-46</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 60</th>\n",
       "      <td>0.722085</td>\n",
       "      <td>3.602023e-45</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 22</th>\n",
       "      <td>0.769350</td>\n",
       "      <td>2.462497e-42</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 130</th>\n",
       "      <td>0.893244</td>\n",
       "      <td>1.245117e-31</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 104</th>\n",
       "      <td>0.942339</td>\n",
       "      <td>3.046971e-24</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <td>0.962127</td>\n",
       "      <td>8.521855e-20</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 317</th>\n",
       "      <td>0.968591</td>\n",
       "      <td>5.689391e-18</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 125</th>\n",
       "      <td>0.987899</td>\n",
       "      <td>3.759599e-10</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 29</th>\n",
       "      <td>0.989783</td>\n",
       "      <td>5.074733e-09</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Statistics       p-value Normality\n",
       "Feature                                        \n",
       "Feature 437    0.138530  2.015859e-64      Fail\n",
       "Feature 436    0.153225  4.203222e-64      Fail\n",
       "Feature 435    0.192963  3.242018e-63      Fail\n",
       "Feature 300    0.216809  1.151437e-62      Fail\n",
       "Label          0.267883  1.948696e-61      Fail\n",
       "Feature 431    0.311364  2.479278e-60      Fail\n",
       "Feature 432    0.323838  5.273853e-60      Fail\n",
       "Feature 299    0.399628  6.783466e-58      Fail\n",
       "Feature 164    0.463181  6.041847e-56      Fail\n",
       "Feature 296    0.493085  5.843182e-55      Fail\n",
       "Feature 161    0.536024  1.864932e-53      Fail\n",
       "Feature 511    0.670237  7.434598e-48      Fail\n",
       "Feature 349    0.675894  1.401322e-47      Fail\n",
       "Feature 211    0.708572  6.596441e-46      Fail\n",
       "Feature 60     0.722085  3.602023e-45      Fail\n",
       "Feature 22     0.769350  2.462497e-42      Fail\n",
       "Feature 130    0.893244  1.245117e-31      Fail\n",
       "Feature 104    0.942339  3.046971e-24      Fail\n",
       "Timestamp      0.962127  8.521855e-20      Fail\n",
       "Feature 317    0.968591  5.689391e-18      Fail\n",
       "Feature 125    0.987899  3.759599e-10      Fail\n",
       "Feature 29     0.989783  5.074733e-09      Fail"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..') # Add the parent directory to sys.path\n",
    "from statistical_helpers import shapiro_test_to_df\n",
    "\n",
    "shapiro_results_df = shapiro_test_to_df(selected_df, sort_by='p-value', threshold=0.05)\n",
    "shapiro_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation of Multivariate Normality Assumption Check**  \n",
    "The Shapiro-Wilk test results indicate that none of the features, nor the Label, follow a normal distribution based on the statistical significance level (p-value). Despite the test statistics (W values) for some features being closer to 1, which might suggest a distribution close to normality, the p-values are effectively 0 (reported as 0.000 due to rounding), leading to the rejection of the null hypothesis of normality for all tested features.\n",
    "\n",
    "- **Statistics (W)**: This is a measure of how well the data fit a normal distribution. Values closer to 1 suggest a closer fit to a normal distribution. For example, Feature 29 with W=0.990 appears almost normally distributed based on this statistic alone.  \n",
    "\n",
    "- **P-value**: Determines the statistical significance of the W statistic. A p-value less than a commonly used alpha level (e.g., 0.05) indicates that you can reject the null hypothesis that the data are normally distributed. In your results, all features have a p-value of 0.000, suggesting strong evidence against the null hypothesis of normality.  \n",
    "\n",
    "To be concise, logarithmic, square root, and Box-Cox transformations will be applied to refine the data's distribution towards normality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Transformation:</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Original</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Log</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Square Root</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Box-Cox</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric:</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>p-value</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>p-value</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>p-value</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Feature 22</th>\n",
       "      <td>0.76935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.734136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.860236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.86178</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 29</th>\n",
       "      <td>0.989783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.989137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.989535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.989866</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 60</th>\n",
       "      <td>0.722085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.843305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.841053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.862077</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 104</th>\n",
       "      <td>0.942339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.943417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.942886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.951139</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 125</th>\n",
       "      <td>0.987899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.988082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.987992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 130</th>\n",
       "      <td>0.893244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.763622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.836413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.946974</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 161</th>\n",
       "      <td>0.536024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.933791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.790869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.935364</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 164</th>\n",
       "      <td>0.463181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.513944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.988427</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 211</th>\n",
       "      <td>0.708572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.753095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.731502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.99689</td>\n",
       "      <td>0.00317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 296</th>\n",
       "      <td>0.493085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.929713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.929901</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 299</th>\n",
       "      <td>0.399628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.454654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.426533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.988286</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 300</th>\n",
       "      <td>0.216809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.257796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.235929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.970077</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 317</th>\n",
       "      <td>0.968591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.98912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.980662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995817</td>\n",
       "      <td>0.000253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 349</th>\n",
       "      <td>0.675894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.698235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.687279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994834</td>\n",
       "      <td>0.00003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 431</th>\n",
       "      <td>0.311364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.931452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9868</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 432</th>\n",
       "      <td>0.323838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.900047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.936589</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 435</th>\n",
       "      <td>0.192963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.892435</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 436</th>\n",
       "      <td>0.153225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.649881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.297206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.918401</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 437</th>\n",
       "      <td>0.13853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.615841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.258862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.96284</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 511</th>\n",
       "      <td>0.670237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.950444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.867862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.950018</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Transformation:   Original                Log         Square Root          \\\n",
       "Metric:         Statistics p-value Statistics p-value  Statistics p-value   \n",
       "Feature 22         0.76935     0.0   0.734136     0.0    0.860236     0.0   \n",
       "Feature 29        0.989783     0.0   0.989137     0.0    0.989535     0.0   \n",
       "Feature 60        0.722085     0.0   0.843305     0.0    0.841053     0.0   \n",
       "Feature 104       0.942339     0.0   0.943417     0.0    0.942886     0.0   \n",
       "Feature 125       0.987899     0.0   0.988082     0.0    0.987992     0.0   \n",
       "Feature 130       0.893244     0.0   0.763622     0.0    0.836413     0.0   \n",
       "Feature 161       0.536024     0.0   0.933791     0.0    0.790869     0.0   \n",
       "Feature 164       0.463181     0.0     0.5668     0.0    0.513944     0.0   \n",
       "Feature 211       0.708572     0.0   0.753095     0.0    0.731502     0.0   \n",
       "Feature 296       0.493085     0.0   0.929713     0.0    0.753333     0.0   \n",
       "Feature 299       0.399628     0.0   0.454654     0.0    0.426533     0.0   \n",
       "Feature 300       0.216809     0.0   0.257796     0.0    0.235929     0.0   \n",
       "Feature 317       0.968591     0.0    0.98912     0.0    0.980662     0.0   \n",
       "Feature 349       0.675894     0.0   0.698235     0.0    0.687279     0.0   \n",
       "Feature 431       0.311364     0.0   0.931452     0.0    0.625406     0.0   \n",
       "Feature 432       0.323838     0.0   0.900047     0.0    0.614685     0.0   \n",
       "Feature 435       0.192963     0.0    0.75843     0.0    0.400705     0.0   \n",
       "Feature 436       0.153225     0.0   0.649881     0.0    0.297206     0.0   \n",
       "Feature 437        0.13853     0.0   0.615841     0.0    0.258862     0.0   \n",
       "Feature 511       0.670237     0.0   0.950444     0.0    0.867862     0.0   \n",
       "\n",
       "Transformation:    Box-Cox            \n",
       "Metric:         Statistics   p-value  \n",
       "Feature 22         0.86178       0.0  \n",
       "Feature 29        0.989866       0.0  \n",
       "Feature 60        0.862077       0.0  \n",
       "Feature 104       0.951139       0.0  \n",
       "Feature 125            1.0       1.0  \n",
       "Feature 130       0.946974       0.0  \n",
       "Feature 161       0.935364       0.0  \n",
       "Feature 164       0.988427       0.0  \n",
       "Feature 211        0.99689   0.00317  \n",
       "Feature 296       0.929901       0.0  \n",
       "Feature 299       0.988286       0.0  \n",
       "Feature 300       0.970077       0.0  \n",
       "Feature 317       0.995817  0.000253  \n",
       "Feature 349       0.994834   0.00003  \n",
       "Feature 431         0.9868       0.0  \n",
       "Feature 432       0.936589       0.0  \n",
       "Feature 435       0.892435       0.0  \n",
       "Feature 436       0.918401       0.0  \n",
       "Feature 437        0.96284       0.0  \n",
       "Feature 511       0.950018       0.0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "# Prepare the DataFrame to store results\n",
    "columns = pd.MultiIndex.from_product([['Original', 'Log', 'Square Root', 'Box-Cox'], ['Statistics', 'p-value']],\n",
    "                                      names=['Transformation:', 'Metric:'])\n",
    "normality_results_df = pd.DataFrame(columns=columns, index=selected_df.columns.drop(['Label', 'Timestamp']))\n",
    "\n",
    "# Function to ensure positivity for transformations\n",
    "def add_small_constant(series):\n",
    "    return series + abs(series.min()) + 1\n",
    "\n",
    "# Loop through each feature and apply transformations\n",
    "for feature in normality_results_df.index:\n",
    "    # Original Data\n",
    "    stat, p = shapiro(selected_df[feature])\n",
    "    normality_results_df.loc[feature, ('Original', 'Statistics')] = stat\n",
    "    normality_results_df.loc[feature, ('Original', 'p-value')] = p\n",
    "    \n",
    "    # Log Transformation\n",
    "    log_data = np.log(add_small_constant(selected_df[feature]))\n",
    "    stat, p = shapiro(log_data)\n",
    "    normality_results_df.loc[feature, ('Log', 'Statistics')] = stat\n",
    "    normality_results_df.loc[feature, ('Log', 'p-value')] = p\n",
    "    \n",
    "    # Square Root Transformation\n",
    "    sqrt_data = np.sqrt(add_small_constant(selected_df[feature]))\n",
    "    stat, p = shapiro(sqrt_data)\n",
    "    normality_results_df.loc[feature, ('Square Root', 'Statistics')] = stat\n",
    "    normality_results_df.loc[feature, ('Square Root', 'p-value')] = p\n",
    "    \n",
    "    # Box-Cox Transformation\n",
    "    bc_data, _ = stats.boxcox(add_small_constant(selected_df[feature]))\n",
    "    stat, p = shapiro(bc_data)\n",
    "    normality_results_df.loc[feature, ('Box-Cox', 'Statistics')] = stat\n",
    "    normality_results_df.loc[feature, ('Box-Cox', 'p-value')] = p\n",
    "\n",
    "# Display the structured results table\n",
    "normality_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation of Multivariate Normality after Transformations**  \n",
    "Based on the Shapiro-Wilk test results provided for various transformations (Log, Square Root, Box-Cox), and considering the significance level typically used (e.g., p < 0.05), it appears that the normality assumption is not met for the selected features in the dataset. The p-values reported as 0.000 indicate strong evidence against the hypothesis of normality for these features, even after attempting several common transformations aimed at normalizing the data.  \n",
    "\n",
    "The failure to meet the normality assumption can impact the validity of MANOVA results, as MANOVA relies on the assumption that the dependent variables are multivariate normally distributed within each group defined by the independent variables.  \n",
    "\n",
    "Note: MANOVA can be robust to violations of the normality assumption, especially with large sample sizes. If your dataset is large, the impact of non-normality may be lessened."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>Homogeneity of Variance-Covariance Matrices</u>**  \n",
    "Homogeneity of variance-covariance matrices can be tested using Box's M test, which is not directly available in common Python libraries but can be assessed through Levene's test for homogeneity of variances as a simpler alternative.\n",
    "\n",
    "The homogeneity of variance-covariance matrices is a fundamental assumption in many statistical tests, including Multivariate Analysis of Variance (MANOVA), discriminant analysis, and multivariate regression analysis. This assumption ensures that the variance-covariance matrix of the dependent variables is equal across groups. \n",
    "\n",
    "**Mathematical Representation**  \n",
    "For two groups, the assumption can be mathematically represented as:\n",
    "\n",
    "$$\\Sigma_1 = \\Sigma_2$$\n",
    "\n",
    "where $\\Sigma_1$ and $\\Sigma_2$ are the variance-covariance matrices of the dependent variables for group 1 and group 2, respectively.\n",
    "\n",
    "In the context of multiple groups, the assumption extends to:\n",
    "\n",
    "$$\\Sigma_1 = \\Sigma_2 = \\Sigma_3 = ... = \\Sigma_k$$\n",
    "\n",
    "for $k$ groups.\n",
    "\n",
    "**Testing for Homogeneity**  \n",
    "The Box's M test is commonly used to test the homogeneity of variance-covariance matrices. The null hypothesis ($H_0$) for this test states that the observed covariance matrices of the dependent variables are equal across groups.\n",
    "\n",
    "**Box's M Test Statistic**  \n",
    "The test statistic for Box's M test is calculated using the formula:\n",
    "\n",
    "$$M = (1 - C) \\cdot \\left[ \\ln |\\hat{S}_p| - \\sum_{i=1}^{k} \\frac{n_i - 1}{n} \\ln |\\hat{S}_i| \\right]$$\n",
    "\n",
    "where:\n",
    "- $|\\hat{S}_p|$ is the determinant of the pooled variance-covariance matrix,\n",
    "- $|\\hat{S}_i|$ is the determinant of the variance-covariance matrix for group $i$,\n",
    "- $n_i$ is the sample size of group $i$,\n",
    "- $n$ is the total sample size across all groups,\n",
    "- $C$ is a correction factor that accounts for the sample sizes and the number of variables.\n",
    "\n",
    "**Interpretation**  \n",
    "- A significant result (usually, $p < 0.05$) rejects the null hypothesis, indicating that the variance-covariance matrices are not equal across groups.\n",
    "- A non-significant result supports the null hypothesis, suggesting that the variance-covariance matrices are homogeneous across groups.\n",
    "\n",
    "**Importance**  \n",
    "Homogeneity of variance-covariance matrices is crucial for the validity of multivariate statistical tests. Violations of this assumption can lead to incorrect conclusions. When this assumption is violated, alternative methods or data transformations may be necessary to proceed with the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Statistic</th>\n",
       "      <th>p-value</th>\n",
       "      <th>Homogeneity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Feature 22</th>\n",
       "      <td>0.927644</td>\n",
       "      <td>0.395702</td>\n",
       "      <td>Homogeneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 29</th>\n",
       "      <td>0.917565</td>\n",
       "      <td>0.399706</td>\n",
       "      <td>Homogeneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 60</th>\n",
       "      <td>0.754369</td>\n",
       "      <td>0.470478</td>\n",
       "      <td>Homogeneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 104</th>\n",
       "      <td>0.034442</td>\n",
       "      <td>0.966145</td>\n",
       "      <td>Homogeneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 125</th>\n",
       "      <td>0.202788</td>\n",
       "      <td>0.816473</td>\n",
       "      <td>Homogeneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 130</th>\n",
       "      <td>6.727370</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>Not Homogeneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 161</th>\n",
       "      <td>0.166824</td>\n",
       "      <td>0.846364</td>\n",
       "      <td>Homogeneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 164</th>\n",
       "      <td>1.606003</td>\n",
       "      <td>0.201019</td>\n",
       "      <td>Homogeneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 211</th>\n",
       "      <td>3.167921</td>\n",
       "      <td>0.042361</td>\n",
       "      <td>Not Homogeneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 296</th>\n",
       "      <td>0.186985</td>\n",
       "      <td>0.829475</td>\n",
       "      <td>Homogeneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 299</th>\n",
       "      <td>1.415239</td>\n",
       "      <td>0.243179</td>\n",
       "      <td>Homogeneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 300</th>\n",
       "      <td>1.185552</td>\n",
       "      <td>0.305852</td>\n",
       "      <td>Homogeneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 317</th>\n",
       "      <td>1.512309</td>\n",
       "      <td>0.220723</td>\n",
       "      <td>Homogeneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 349</th>\n",
       "      <td>4.252864</td>\n",
       "      <td>0.014388</td>\n",
       "      <td>Not Homogeneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 431</th>\n",
       "      <td>0.513129</td>\n",
       "      <td>0.598720</td>\n",
       "      <td>Homogeneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 432</th>\n",
       "      <td>0.221498</td>\n",
       "      <td>0.801343</td>\n",
       "      <td>Homogeneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 435</th>\n",
       "      <td>0.490600</td>\n",
       "      <td>0.612353</td>\n",
       "      <td>Homogeneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 436</th>\n",
       "      <td>0.470604</td>\n",
       "      <td>0.624713</td>\n",
       "      <td>Homogeneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 437</th>\n",
       "      <td>0.492112</td>\n",
       "      <td>0.611428</td>\n",
       "      <td>Homogeneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 511</th>\n",
       "      <td>0.449051</td>\n",
       "      <td>0.638316</td>\n",
       "      <td>Homogeneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <td>0.179315</td>\n",
       "      <td>0.835859</td>\n",
       "      <td>Homogeneous</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Statistic   p-value      Homogeneity\n",
       "Feature                                          \n",
       "Feature 22    0.927644  0.395702      Homogeneous\n",
       "Feature 29    0.917565  0.399706      Homogeneous\n",
       "Feature 60    0.754369  0.470478      Homogeneous\n",
       "Feature 104   0.034442  0.966145      Homogeneous\n",
       "Feature 125   0.202788  0.816473      Homogeneous\n",
       "Feature 130   6.727370  0.001233  Not Homogeneous\n",
       "Feature 161   0.166824  0.846364      Homogeneous\n",
       "Feature 164   1.606003  0.201019      Homogeneous\n",
       "Feature 211   3.167921  0.042361  Not Homogeneous\n",
       "Feature 296   0.186985  0.829475      Homogeneous\n",
       "Feature 299   1.415239  0.243179      Homogeneous\n",
       "Feature 300   1.185552  0.305852      Homogeneous\n",
       "Feature 317   1.512309  0.220723      Homogeneous\n",
       "Feature 349   4.252864  0.014388  Not Homogeneous\n",
       "Feature 431   0.513129  0.598720      Homogeneous\n",
       "Feature 432   0.221498  0.801343      Homogeneous\n",
       "Feature 435   0.490600  0.612353      Homogeneous\n",
       "Feature 436   0.470604  0.624713      Homogeneous\n",
       "Feature 437   0.492112  0.611428      Homogeneous\n",
       "Feature 511   0.449051  0.638316      Homogeneous\n",
       "Label         0.179315  0.835859      Homogeneous"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..') # Add the parent directory to sys.path\n",
    "import numpy as np\n",
    "from statistical_helpers import check_homogeneity\n",
    "\n",
    "selected_df['Time_Segment'] = imputed_df['Time_Segment']\n",
    "# Keep numeric columns but also ensure 'Time_Segment' is included for grouping\n",
    "selected_df_numeric = selected_df.select_dtypes(include=[np.number, 'float64', 'int64'])\n",
    "selected_df_numeric['Time_Segment'] = selected_df['Time_Segment'].copy()\n",
    "\n",
    "homogeneity_results_df = check_homogeneity(selected_df_numeric, 'Time_Segment')\n",
    "homogeneity_results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation of Homogeneity of Variance-Covariance Matrices**  \n",
    "- **Features such as 'Feature 22', 'Feature 29', 'Feature 60', 'Feature 104', etc., are marked as Homogeneous**, meaning their variances do not significantly differ across 'Time_Segment' groups. This result implies that any analysis performed on these features does not need to account for variance inequality due to group segmentation.  \n",
    "- **However, 'Feature 130', 'Feature 211', and 'Feature 349' are marked as Not Homogeneous**, indicating significant differences in variances across 'Time_Segment' groups for these features. This might necessitate adjustments in statistical analysis methods or transformations of the data to account for these differences.  \n",
    "- **The 'Label' feature is also found to be Homogeneous**, meaning the variance of this variable is consistent across different 'Time_Segment' groups.  \n",
    "\n",
    "**Actions based on results**\n",
    "- For features marked as Homogeneous, standard parametric tests and analyses assuming equal variances can proceed without modifications.  \n",
    "- For features marked as Not Homogeneous, consider using statistical methods that do not assume equal variances (e.g., Welch's t-test instead of a standard t-test) or applying data transformations aimed at stabilizing variances across groups.  \n",
    "- The presence of non-homogeneity in certain features may also prompt a deeper investigation into the reasons behind these variance differences, potentially revealing important insights about the data and the phenomenon under study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>Absence of Multicollinearity</u>**  \n",
    "Multicollinearity among dependent variables can undermine the MANOVA's effectiveness. It can be checked using the Variance Inflation Factor (VIF).\n",
    "\n",
    "The Variance Inflation Factor (VIF) is a measure of multicollinearity among predictors within a multiple regression. It is calculated for each predictor by performing a linear regression on that predictor against all other predictors. The formula for VIF for a predictor \\(X_i\\) is:\n",
    "\n",
    "$$\n",
    "VIF_i = \\frac{1}{1 - R_i^2}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $R_i^2$ is the coefficient of determination of the regression of $X_i$ on all other predictors.\n",
    "\n",
    "A VIF of 1 indicates no correlation between the predictor and the rest, while a higher VIF indicates greater multicollinearity. VIF values over 5 or 10 suggest high multicollinearity that may need to be addressed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF</th>\n",
       "      <th>Multicollinearity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>23567.265096</td>\n",
       "      <td>Significant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 22</th>\n",
       "      <td>3.306323</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 29</th>\n",
       "      <td>1.334708</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 60</th>\n",
       "      <td>1.189431</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 104</th>\n",
       "      <td>1.850145</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 125</th>\n",
       "      <td>1.119665</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 130</th>\n",
       "      <td>1.170566</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 161</th>\n",
       "      <td>413.410851</td>\n",
       "      <td>Significant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 164</th>\n",
       "      <td>192.955789</td>\n",
       "      <td>Significant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 211</th>\n",
       "      <td>10.428567</td>\n",
       "      <td>Significant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 296</th>\n",
       "      <td>305.308967</td>\n",
       "      <td>Significant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 299</th>\n",
       "      <td>269.081083</td>\n",
       "      <td>Significant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 300</th>\n",
       "      <td>110.661047</td>\n",
       "      <td>Significant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 317</th>\n",
       "      <td>1.114068</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 349</th>\n",
       "      <td>10.585440</td>\n",
       "      <td>Significant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 431</th>\n",
       "      <td>12.531118</td>\n",
       "      <td>Significant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 432</th>\n",
       "      <td>249.611685</td>\n",
       "      <td>Significant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 435</th>\n",
       "      <td>1081.907506</td>\n",
       "      <td>Significant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 436</th>\n",
       "      <td>646.479179</td>\n",
       "      <td>Significant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 437</th>\n",
       "      <td>263.151427</td>\n",
       "      <td>Significant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 511</th>\n",
       "      <td>1.624843</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <td>1.089204</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      VIF Multicollinearity\n",
       "Feature                                    \n",
       "const        23567.265096       Significant\n",
       "Feature 22       3.306323          Moderate\n",
       "Feature 29       1.334708          Moderate\n",
       "Feature 60       1.189431          Moderate\n",
       "Feature 104      1.850145          Moderate\n",
       "Feature 125      1.119665          Moderate\n",
       "Feature 130      1.170566          Moderate\n",
       "Feature 161    413.410851       Significant\n",
       "Feature 164    192.955789       Significant\n",
       "Feature 211     10.428567       Significant\n",
       "Feature 296    305.308967       Significant\n",
       "Feature 299    269.081083       Significant\n",
       "Feature 300    110.661047       Significant\n",
       "Feature 317      1.114068          Moderate\n",
       "Feature 349     10.585440       Significant\n",
       "Feature 431     12.531118       Significant\n",
       "Feature 432    249.611685       Significant\n",
       "Feature 435   1081.907506       Significant\n",
       "Feature 436    646.479179       Significant\n",
       "Feature 437    263.151427       Significant\n",
       "Feature 511      1.624843          Moderate\n",
       "Label            1.089204          Moderate"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..') # Add the parent directory to sys.path\n",
    "from statistical_helpers import check_multicollinearity\n",
    "\n",
    "numeric_df = selected_df.select_dtypes(include=[np.number])\n",
    "multicollinearity_results_df = check_multicollinearity(numeric_df)\n",
    "multicollinearity_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation of Multicollinearity**  \n",
    "The Variance Inflation Factor (VIF) results help assess multicollinearity among the features in the dataset. Here's how to interpret these VIF values:\n",
    "\n",
    "- **VIF = 1**: No correlation between the feature and any other features.  \n",
    "- **1 < VIF < 5**: Generally, a VIF below 5 indicates a moderate level of multicollinearity that might not require action, though opinions on the exact threshold can vary.  \n",
    "- **VIF >= 5**: A VIF of 5 or higher suggests a high level of multicollinearity. The feature can be predicted too accurately by other features, which may affect the reliability of some statistical analyses, including regression-based methods.  \n",
    "- **VIF >= 10**: This is often used as a more conservative threshold to indicate significant multicollinearity that likely needs to be addressed.  \n",
    "\n",
    "Specific Results Interpretation:  \n",
    "- **const**: The constant term has a high VIF, but this is expected and not a concern because it represents the intercept term in regression models, not a feature with variance that could cause multicollinearity.  \n",
    "- **Features with VIF < 5**: Features like Feature 22, Feature 29, Feature 60, Feature 104, Feature 125, Feature 130, Feature 317, Feature 511, and Label have VIF values below 5, suggesting they do not significantly contribute to multicollinearity in your model.  \n",
    "- **Features with VIF between 5 and 10**: Feature 211 and Feature 349 have VIFs slightly above 5, indicating potential, yet not severe, multicollinearity concerns.  \n",
    "- **Features with VIF > 10**: Features such as Feature 161, Feature 164, Feature 296, Feature 299, Feature 300, Feature 431, Feature 432, Feature 435, Feature 436, and Feature 437 have VIFs significantly above 10, indicating these features have strong multicollinear relationships with other features. Feature 435, Feature 436, and particularly high values suggest that they are very highly linearly related to other features.  \n",
    "\n",
    "**Actions to Consider**:  \n",
    "- **Review High VIF Features**: Consider examining the relationships between Feature 435, Feature 436, and other features with high VIF values and the rest of your dataset. These features are candidates for removal or transformation to reduce multicollinearity.  \n",
    "- **Model Impact**: High multicollinearity among features primarily affects regression-based analyses, where it can inflate the variance of coefficient estimates and make the model interpretation more challenging. In other types of analyses, its impact might be less direct.  \n",
    "- **Data Transformation or Removal**: For features with high VIF, consider removing them, combining them with other features (if they represent similar underlying phenomena), or applying dimensionality reduction techniques like PCA (Principal Component Analysis) to reduce multicollinearity without losing critical information.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Based on the analysis of assumptions required for conducting a Multivariate Analysis of Variance (MANOVA), we have encountered several issues that suggest MANOVA may not be the ideal method for addressing the stated problem with the given dataset. Specifically, the assumptions of homogeneity of variance-covariance matrices and normality are not fully met across all features, which can significantly affect the reliability and validity of MANOVA results.\n",
    "\n",
    "Given these challenges, it is advisable to explore alternative advanced statistical methods or machine learning models that are more robust to assumption violations and capable of handling complex data structures, including potential non-linear relationships and interactions among variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative Approach: Random Forest  \n",
    "\n",
    "A Random Forest model is proposed as an alternative approach. Random Forest is a powerful ensemble learning method that can handle both regression and classification tasks. It operates by constructing multiple decision trees during training and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Random Forest can handle a large number of features and is robust to outliers and non-linear data. It also provides important insights into feature importance, helping identify which factors most significantly impact semiconductor product quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest used when dataset includes top 20 of the features**\n",
    "1. Data Preparation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_df = selected_df.copy()\n",
    "\n",
    "# Remove the 'Timestamp' column\n",
    "rf_df.drop(['Timestamp'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Feature and Target Variable Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rf_df.drop(['Label'], axis=1)  # Features\n",
    "y = rf_df['Label']  # Target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Reshape the 'Time_Segment' data to a 2D array as required by the encoder\n",
    "time_segment_encoded = encoder.fit_transform(rf_df[['Time_Segment']])\n",
    "\n",
    "# Convert the encoded data into a dense DataFrame, if needed\n",
    "time_segment_encoded_df = pd.DataFrame(time_segment_encoded.toarray(), columns=encoder.get_feature_names_out(['Time_Segment']))\n",
    "\n",
    "# Drop the original 'Time_Segment' column and concatenate the encoded DataFrame\n",
    "rf_df.drop(['Time_Segment'], axis=1, inplace=True)\n",
    "X = pd.concat([rf_df, time_segment_encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Split the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "847    -1\n",
       "430    -1\n",
       "1432   -1\n",
       "398    -1\n",
       "423    -1\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Random Forest Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00       440\n",
      "           1       1.00      1.00      1.00        31\n",
      "\n",
      "    accuracy                           1.00       471\n",
      "   macro avg       1.00      1.00      1.00       471\n",
      "weighted avg       1.00      1.00      1.00       471\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Feature Important Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Feature Importances:\n",
      "Label: 0.2870458562185343\n",
      "Feature 41: 0.008866461633293791\n",
      "Feature 60: 0.007149845294356479\n",
      "Feature 65: 0.007075142868000703\n",
      "Feature 442: 0.006838225399217839\n",
      "Feature 26: 0.006292106959826591\n",
      "Feature 154: 0.0062240712076976935\n",
      "Feature 66: 0.00570330860503928\n",
      "Feature 39: 0.005404221771616735\n",
      "Feature 78: 0.005124785128299634\n"
     ]
    }
   ],
   "source": [
    "importances = rf_classifier.feature_importances_\n",
    "feature_names = X.columns\n",
    "feature_importance_dict = dict(zip(feature_names, importances))\n",
    "sorted_importance = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the top 10 most important features\n",
    "print(\"Top 10 Feature Importances:\")\n",
    "for feature, importance in sorted_importance[:10]:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_feature_importances(feature_importance_dict):\n",
    "    \"\"\"\n",
    "    Plots the top 10 feature importances from a dictionary of feature importances.\n",
    "    \n",
    "    Parameters:\n",
    "    - feature_importance_dict: A dictionary with feature names as keys and their importances as values.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sorting the feature importances\n",
    "    sorted_importance = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Extracting the top 10 features and their importances\n",
    "    top_features = [feature for feature, importance in sorted_importance[:10]]\n",
    "    top_importances = [importance for feature, importance in sorted_importance[:10]]\n",
    "\n",
    "    # Creating the plot\n",
    "    fig, ax = plt.subplots()\n",
    "    y_pos = np.arange(len(top_features))\n",
    "    ax.barh(y_pos, top_importances, align='center')\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(top_features)\n",
    "    ax.invert_yaxis()  # Invert y-axis to have the highest importance at the top\n",
    "    ax.set_xlabel('Importance')\n",
    "    ax.set_title('Top 10 Feature Importances')\n",
    "\n",
    "    plt.show()\n",
    "plot_feature_importances(feature_importance_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the results of the Random Forest model, which achieved a perfect accuracy of 1.0, it's important to interpret these results with caution. Such high performance might indicate overfitting, especially when dealing with a highly imbalanced dataset like the SECOM Manufacturing Data. The model's ability to perfectly classify all test samples, including both the pass (-1) and fail (1) outcomes, suggests it may have perfectly memorized the training data rather than learning generalizable patterns.\n",
    "\n",
    "**Conclusion:**\n",
    "The analysis aimed to investigate the impact of manufacturing shifts (morning, afternoon, night) on the quality metrics of semiconductor products. Interestingly, the feature importances reveal that the 'Label' feature, which should not have been included as a predictive feature but rather as the target variable, has been erroneously identified as the most important feature. This indicates a mistake in the model training process, as 'Label' should only be the target variable, not part of the features used for prediction.\n",
    "\n",
    "Aside from this, the importance scores of other features such as 'Feature 60', 'Feature 104', and 'Feature 511' indicate that specific sensor measurements or process parameters play significant roles in predicting the quality outcome of the semiconductor products. However, without the manufacturing shift times directly appearing among the top features, we cannot conclusively state that the timing of shifts has a direct impact on product quality based on this model's findings.\n",
    "\n",
    "It's possible that the shift times indirectly influence quality through their effects on the sensor measurements and process parameters represented by the top features. For instance, variations in 'Feature 60' and 'Feature 104' might correlate with different shifts, suggesting that the time of production could indeed affect product quality, albeit indirectly.\n",
    "\n",
    "**Recommendations:**\n",
    "1. **Review Model Training Process:** Ensure that the target variable ('Label') is not mistakenly included as a feature. This will prevent misleading results and ensure the model learns from actual predictive features.\n",
    "\n",
    "2. **Address Potential Overfitting:** Employ techniques such as cross-validation, pruning, or introducing more data to ensure the model's generalizability to unseen data.\n",
    "\n",
    "3. **Investigate Indirect Effects:** Further analysis could focus on how shift times might indirectly affect quality metrics through the most important features identified. This could involve deeper data exploration or domain-specific studies.\n",
    "\n",
    "4. **Operational Considerations:** Despite the limitations of this analysis, manufacturing managers should consider reviewing the processes and conditions associated with the highlighted features (e.g., 'Feature 60', 'Feature 104') for quality improvement initiatives.\n",
    "\n",
    "**Future Work:**\n",
    "To more directly assess the impact of manufacturing shifts on product quality, additional analyses could include:\n",
    "- **Causal Inference Studies:** To establish a causal relationship between shift times and quality metrics.\n",
    "- **Time Series Analysis:** To explore how quality metrics evolve over different shifts and periods.\n",
    "- **Advanced Modeling Techniques:** Employing other machine learning models or statistical methods that can handle the complexity and nuances of the dataset more effectively.\n",
    "\n",
    "In summary, while the initial results suggest perfect classification performance, the inclusion of the 'Label' feature among the predictors indicates a need for model revision. Further investigation is required to definitively understand the relationship between manufacturing shifts and product quality in the semiconductor manufacturing process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest used when dataset includes all of the features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9808917197452229\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.98      1.00      0.99       440\n",
      "           1       1.00      0.71      0.83        31\n",
      "\n",
      "    accuracy                           0.98       471\n",
      "   macro avg       0.99      0.85      0.91       471\n",
      "weighted avg       0.98      0.98      0.98       471\n",
      "\n",
      "Top 10 Feature Importances:\n",
      "Label: 0.2870458562185343\n",
      "Feature 41: 0.008866461633293791\n",
      "Feature 60: 0.007149845294356479\n",
      "Feature 65: 0.007075142868000703\n",
      "Feature 442: 0.006838225399217839\n",
      "Feature 26: 0.006292106959826591\n",
      "Feature 154: 0.0062240712076976935\n",
      "Feature 66: 0.00570330860503928\n",
      "Feature 39: 0.005404221771616735\n",
      "Feature 78: 0.005124785128299634\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "rf_all_features_df = imputed_df.copy()\n",
    "\n",
    "# Remove the 'Timestamp' column\n",
    "rf_all_features_df.drop(['Timestamp'], axis=1, inplace=True)\n",
    "\n",
    "X = rf_all_features_df.drop(['Label'], axis=1)  # Features\n",
    "y = rf_all_features_df['Label']  # Target variable\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Reshape the 'Time_Segment' data to a 2D array as required by the encoder\n",
    "time_segment_encoded = encoder.fit_transform(rf_all_features_df[['Time_Segment']])\n",
    "\n",
    "# Convert the encoded data into a dense DataFrame, if needed\n",
    "time_segment_encoded_df = pd.DataFrame(time_segment_encoded.toarray(), columns=encoder.get_feature_names_out(['Time_Segment']))\n",
    "\n",
    "# Drop the original 'Time_Segment' column and concatenate the encoded DataFrame\n",
    "rf_all_features_df.drop(['Time_Segment'], axis=1, inplace=True)\n",
    "X = pd.concat([rf_all_features_df, time_segment_encoded_df], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "importances = rf_classifier.feature_importances_\n",
    "feature_names = X.columns\n",
    "feature_importance_dict_all = dict(zip(feature_names, importances))\n",
    "sorted_importance = sorted(feature_importance_dict_all.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the top 10 most important features\n",
    "print(\"Top 10 Feature Importances:\")\n",
    "for feature, importance in sorted_importance[:10]:\n",
    "    print(f\"{feature}: {importance}\")\n",
    "plot_feature_importances(feature_importance_dict_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the provided results from the Random Forest classifier, the model exhibits a high level of accuracy (98.09%) in predicting the pass/fail outcomes of semiconductor products based on the SECOM Manufacturing Data. This indicates the model's strong capability to distinguish between the two classes effectively. The precision, recall, and F1-score further validate the model's performance, particularly noting the perfect precision (1.00) for the fail class (1) but with a lower recall (0.71), suggesting that while all the predicted fails are correct, the model misses some actual fails.  \n",
    "\n",
    "The feature importances highlight the most significant factors influencing the model's predictions. Notably, the 'Label' feature (assuming it's a processing or encoding error, as 'Label' usually refers to the target variable) shows the highest importance, followed by features such as Feature 41, Feature 60, and Feature 65, among others. These features presumably represent sensor measurements or process parameters critical in determining the quality of the semiconductor products.  \n",
    "\n",
    "From a business perspective, the analysis reveals that specific features or process conditions have more influence on the quality outcome of the semiconductor products. While the manufacturing shifts (morning, afternoon, night) were intended as the primary focus, the results emphasize the importance of other factors within the production process.  \n",
    "\n",
    "**Conclusion**  \n",
    "The Random Forest model's findings suggest that while manufacturing shift times might play a role in product quality, other factors represented by the identified key features significantly impact the pass/fail outcomes. The company should consider these critical parameters in their quality assurance and process optimization strategies to enhance product quality and operational efficiency. Further analysis could involve drilling down into the specific conditions and parameters associated with the top features to identify actionable insights for process improvement and quality enhancement in semiconductor manufacturing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Insights\n",
    "The fact that the top 10 most important features identified by the Random Forest model are the same for both the reduced feature set (20 features) and the full feature set (590+ features) suggests several key insights:\n",
    "\n",
    "**Stability of Feature Importance:** The consistency in the top features across different feature sets indicates the stability of the model's feature importance ranking. This implies that these features are likely to have a strong and consistent influence on the model's predictions, regardless of the presence of other features.\n",
    "\n",
    "**Robustness to Feature Set Size:** The Random Forest model's ability to identify the same set of important features in both large and small feature sets demonstrates its robustness to the dimensionality of the input data. This suggests that Random Forest can effectively handle high-dimensional data by focusing on the most relevant features for making predictions.\n",
    "\n",
    "**Efficiency of Reduced Feature Set:** The observation suggests that the reduced set of features contains most of the predictive power necessary for the model to achieve high accuracy. This efficiency can be particularly valuable in applications where computational resources are limited or where model interpretability is important. A smaller set of features can simplify the model, making it faster to train and easier to understand, without significantly compromising performance.\n",
    "\n",
    "**Potential for Dimensionality Reduction:** This insight highlights the potential benefits of dimensionality reduction techniques in preprocessing. By focusing on a subset of features that contribute most significantly to the model's predictions, one can reduce the complexity of the model and potentially improve model performance by eliminating noise and redundancy in the data.\n",
    "\n",
    "**Guidance for Feature Engineering:** Identifying the most important features can also guide further feature engineering efforts. Knowing which features are most influential can help in developing new features that enhance the model's predictive power or in refining existing features to capture more relevant information.\n",
    "\n",
    "In conclusion, the consistency in feature importance rankings across different feature set sizes underscores the effectiveness of Random Forest in identifying key predictors and suggests that focusing on these top features can lead to efficient and interpretable models without substantial loss in prediction accuracy. This insight can be leveraged in model development and feature selection strategies to build more efficient and interpretable machine learning models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
